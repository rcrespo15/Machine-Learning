{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3f4764b47b06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A: one solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that I want to find the $w$ that minimizes $\\frac{1}{2n}||Xw - y||_2^2$. In this part, X is full rank, and $y \\in range(X)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.normal(scale = 20, size=(100,10))\n",
    "print(np.linalg.matrix_rank(X)) # confirm that the matrix is full rank\n",
    "# Theoretical optimal solution\n",
    "w = np.random.normal(scale = 10, size = (10,1))\n",
    "y = X.dot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(X, y, w_actual, threshold, max_iterations, step_size, gd=False):\n",
    "    if isinstance(step_size, float):\n",
    "        step_size_func = lambda i: step_size\n",
    "    else:\n",
    "        step_size_func = step_size\n",
    "        \n",
    "    # run 10 gradient descent at the same time, for averaging purpose\n",
    "    # w_guesses stands for the current iterates (for each run)\n",
    "    w_guesses = [np.zeros((X.shape[1], 1)) for _ in range(10)]\n",
    "    n = X.shape[0]\n",
    "    error = []\n",
    "    it = 0\n",
    "    above_threshold = True\n",
    "    previous_w = np.array(w_guesses)\n",
    "    \n",
    "    while it < max_iterations and above_threshold:\n",
    "        it += 1\n",
    "        curr_error = 0\n",
    "        for j in range(len(w_guesses)):\n",
    "            if gd:\n",
    "                # Your code, implement the gradient for GD\n",
    "                # sample_gradient = ?\n",
    "            else:\n",
    "                # Your code, implement the gradient for SGD\n",
    "                # sample_gradient =  ?\n",
    "                \n",
    "            # Your code: implement the gradient update\n",
    "            # learning rate at this step is given by step_size_func(it)            \n",
    "            # w_guesses[j] = ?\n",
    "            \n",
    "            curr_error += np.linalg.norm(w_guesses[j]-w_actual)\n",
    "        error.append(curr_error/10)\n",
    "        \n",
    "        diff = np.array(previous_w) - np.array(w_guesses)\n",
    "        diff = np.mean(np.linalg.norm(diff, axis=1))\n",
    "        above_threshold = (diff > threshold)\n",
    "        previous_w = np.array(w_guesses)\n",
    "    return w_guesses, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "its = 5000\n",
    "w_guesses, error = sgd(X, y, w, 1e-10, its, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = [i for i in range(len(error))]\n",
    "#plt.semilogy(iterations, error, label = \"Average error in w\")\n",
    "plt.semilogy(iterations, error, label = \"Average error in w\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Norm of $w^t - w^*$\",  usetex=True)\n",
    "plt.title(\"Average Error vs Iterations for SGD with exact sol\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Required iterations: \", len(error))\n",
    "average_error = np.mean([np.linalg.norm(w-w_guess) for w_guess in w_guesses])\n",
    "print(\"Final average error: \", average_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B: No solutions, constant step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = y + np.random.normal(scale=5, size = y.shape)\n",
    "w=np.linalg.inv(X.T @ X) @ X.T @ y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "its = 5000\n",
    "w_guesses2, error2 = sgd(X, y2, w, 1e-5, its, 0.0001)\n",
    "w_guesses3, error3 = sgd(X, y2, w, 1e-5, its, 0.00001)\n",
    "w_guesses4, error4 = sgd(X, y2, w, 1e-5, its, 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_guess_gd, error_gd = sgd(X, y2, w, 1e-5, its, 0.001, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy([i for i in range(len(error2))], error2, label=\"SGD, lr = 0.0001\")\n",
    "plt.semilogy([i for i in range(len(error3))], error3, label=\"SGD, lr = 0.00001\")\n",
    "plt.semilogy([i for i in range(len(error4))], error4, label=\"SGD, lr = 0.000001\")\n",
    "plt.semilogy([i for i in range(len(error_gd))], error_gd, label=\"GD, lr = 0.00001\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Norm of $w^t - w^*$\",  usetex=True)\n",
    "plt.title(\"Total Error vs Iterations for SGD without exact sol\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Required iterations, lr = 0.0001: \", len(error2))\n",
    "average_error = np.mean([np.linalg.norm(w-w_guess) for w_guess in w_guesses2])\n",
    "print(\"Final average error: \", average_error)\n",
    "\n",
    "print(\"Required iterations, lr = 0.00001: \", len(error3))\n",
    "average_error = np.mean([np.linalg.norm(w-w_guess) for w_guess in w_guesses3])\n",
    "print(\"Final average error: \", average_error)\n",
    "\n",
    "print(\"Required iterations, lr = 0.000001: \", len(error4))\n",
    "average_error = np.mean([np.linalg.norm(w-w_guess) for w_guess in w_guesses4])\n",
    "print(\"Final average error: \", average_error)\n",
    "\n",
    "print(\"Required iterations, GD: \", len(error_gd))\n",
    "average_error = np.mean([np.linalg.norm(w-w_guess) for w_guess in w_guess_gd])\n",
    "print(\"Final average error: \", average_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C: No solutions, decreasing step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "its = 5000\n",
    "def step_size(step):\n",
    "    if step < 500:\n",
    "        return 1e-4 \n",
    "    if step < 1500:\n",
    "        return 1e-5\n",
    "    if step < 3000:\n",
    "        return 3e-6\n",
    "    return 1e-6\n",
    "\n",
    "w_guesses_variable, error_variable = sgd(X, y2, w, 1e-10, its, step_size, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.semilogy([i for i in range(len(error_variable))], error_variable, label=\"Average error, decreasing lr\")\n",
    "plt.semilogy([i for i in range(len(error2))], error2, label=\"Average error, lr = 0.0001\")\n",
    "plt.semilogy([i for i in range(len(error3))], error3, label=\"Average error, lr = 0.00001\")\n",
    "plt.semilogy([i for i in range(len(error4))], error4, label=\"Average error, lr = 0.000001\")\n",
    "\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Norm of $w^t - w^*$\",  usetex=True)\n",
    "plt.title(\"Error vs Iterations for SGD with no exact sol\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Required iterations, variable lr: \", len(error_variable))\n",
    "average_error = np.mean([np.linalg.norm(w-w_guess) for w_guess in w_guesses_variable])\n",
    "print(\"Average error with decreasing lr:\", average_error)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
